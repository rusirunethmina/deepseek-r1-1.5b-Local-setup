![Group 1171276039](https://static.euronews.com/articles/stories/09/00/69/48/1200x675_cmsv2_4b3d5a33-60f6-5a9c-b545-18ffed37b354-9006948.jpg)

setup deepseek-r1:1.5b in local machine simple web UI - UI - HTML & tailwindcss | Backend - python (Flask) & ollama


Ollama is a platform that enables users to run large language models (LLMs) locally on their machines, supporting models like Llama 3.3, DeepSeek-R1, Phi-4, Mistral, and Gemma 2.


## Contributing
We welcome contributions from the community. Please refer to the [CONTRIBUTING.md](./CONTRIBUTING.md) file for guidelines on how to contribute to this project. Your contributions are invaluable in helping us improve and grow.
